{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Classic CNN Notebook"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries and Seed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import random\n","from datetime import datetime\n","\n","import splitfolders\n","\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import tensorflow as tf\n","from keras.models import load_model\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","from keras.regularizers import l2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Checking tensorflow version\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:03.88075Z","iopub.status.busy":"2021-11-19T14:28:03.88046Z","iopub.status.idle":"2021-11-19T14:28:03.890738Z","shell.execute_reply":"2021-11-19T14:28:03.889892Z","shell.execute_reply.started":"2021-11-19T14:28:03.880717Z"},"papermill":{"duration":0.022007,"end_time":"2021-11-17T09:01:03.281682","exception":false,"start_time":"2021-11-17T09:01:03.259675","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Setting seed for reproducibility\n","seed = 42\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Splitting the main dataset into train and val\n","dataset_dir = '../datasetNoTest'\n","\n","if not(os.path.exists('../datasetNoTest')) :\n","    print('splitting')\n","    splitfolders.ratio('dataset', output='datasetNoTest', seed=seed, ratio=(0.8, 0.2))\n","\n","# Setting dataset directories\n","training_dir = os.path.join(dataset_dir, 'train')\n","validation_dir = os.path.join(dataset_dir, 'val')"]},{"cell_type":"markdown","metadata":{},"source":["## Model Parameters and Classes Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:03.91742Z","iopub.status.busy":"2021-11-19T14:28:03.916864Z","iopub.status.idle":"2021-11-19T14:28:03.930383Z","shell.execute_reply":"2021-11-19T14:28:03.929733Z","shell.execute_reply.started":"2021-11-19T14:28:03.917383Z"},"papermill":{"duration":0.021183,"end_time":"2021-11-17T09:01:03.38529","exception":false,"start_time":"2021-11-17T09:01:03.364107","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Labels of the dataset for classification\n","labels = ['Apple',              # 0\n","          'Blueberry',          # 1\n","          \"Cherry\",             # 2\n","          \"Corn\",               # 3\n","          \"Grape\",              # 4\n","          \"Orange\",             # 5\n","          \"Peach\",              # 6\n","          \"Pepper\",             # 7\n","          \"Potato\",             # 8\n","          \"Raspberry\",          # 9\n","          \"Soybean\",            # 10\n","          \"Squash\",             # 11\n","          \"Strawberry\",         # 12\n","          \"Tomato\"]             # 13"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Input Parameters\n","img_w = 256\n","img_h = 256\n","input_shape = (256, 256, 3)\n","classes = 14\n","\n","# Training Parameters\n","epochs = 90\n","batch_size = 64\n","reg_rate = 0.001\n","\n","# Earlystopping Parameters\n","early_stopping = False\n","patience_epochs = 9"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:03.932236Z","iopub.status.busy":"2021-11-19T14:28:03.931781Z","iopub.status.idle":"2021-11-19T14:28:03.941543Z","shell.execute_reply":"2021-11-19T14:28:03.940682Z","shell.execute_reply.started":"2021-11-19T14:28:03.932202Z"},"trusted":true},"outputs":[],"source":["# This calculate the weights for all the classes\n","# by counting the number of images for each class\n","# and dividing by the number of total images\n","category_weight = {}\n","elements_per_class = {}\n","\n","for i in range(classes):\n","    category_weight[i] = 0.0\n","\n","for i in range(classes):\n","    elements_per_class[i] = 0\n","\n","_, classes_directories, _ = next(os.walk(training_dir))\n","\n","for img_class in classes_directories:\n","    class_dir = training_dir + '/' + str(img_class)\n","    _, _, files = next(os.walk(class_dir))\n","    elements_per_class[labels.index(img_class)] = len(files)\n","\n","total_images = sum(elements_per_class.values())\n","\n","for i in category_weight.keys():\n","    category_weight[i] = total_images / (classes * elements_per_class[i])"]},{"cell_type":"markdown","metadata":{},"source":["## Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:06.960192Z","iopub.status.busy":"2021-11-19T14:28:06.959427Z","iopub.status.idle":"2021-11-19T14:28:06.970368Z","shell.execute_reply":"2021-11-19T14:28:06.969493Z","shell.execute_reply.started":"2021-11-19T14:28:06.960152Z"},"papermill":{"duration":0.022752,"end_time":"2021-11-17T09:01:03.525827","exception":false,"start_time":"2021-11-17T09:01:03.503075","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["aug_train_data_gen =  ImageDataGenerator(rotation_range=10,\n","                                         width_shift_range=0.2,\n","                                         height_shift_range=0.2,\n","                                         zoom_range=0.2,\n","                                         horizontal_flip=True,\n","                                         brightness_range=[0.2,1.2],\n","                                         vertical_flip=True,\n","                                         fill_mode='nearest',\n","                                         rescale=1/255.) \n","\n","valid_data_gen = ImageDataGenerator(rescale=1/255.)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:06.974043Z","iopub.status.busy":"2021-11-19T14:28:06.973564Z","iopub.status.idle":"2021-11-19T14:28:08.354076Z","shell.execute_reply":"2021-11-19T14:28:08.353171Z","shell.execute_reply.started":"2021-11-19T14:28:06.974002Z"},"papermill":{"duration":4.578505,"end_time":"2021-11-17T09:01:08.118643","exception":false,"start_time":"2021-11-17T09:01:03.540138","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["\n","aug_train_gen = aug_train_data_gen.flow_from_directory(directory=training_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=labels,\n","                                               batch_size=batch_size,\n","                                               shuffle=True,\n","                                               seed=seed)\n","\n","valid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n","                                               target_size=(256, 256),\n","                                               color_mode='rgb',\n","                                               classes=labels,\n","                                               batch_size=batch_size,\n","                                               shuffle=False,\n","                                               seed=seed)"]},{"cell_type":"markdown","metadata":{},"source":["## Neural Network Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:08.361907Z","iopub.status.busy":"2021-11-19T14:28:08.361339Z","iopub.status.idle":"2021-11-19T14:28:08.384382Z","shell.execute_reply":"2021-11-19T14:28:08.383701Z","shell.execute_reply.started":"2021-11-19T14:28:08.361868Z"},"trusted":true},"outputs":[],"source":["def build_model(input_shape):\n","\n","\n","    # Layer Input -------------------------------------------------------\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","    \n","\n","\n","    # Layer 1 -----------------------------------------------------------\n","    conv1 = tfkl.Conv2D(\n","        filters=25,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        kernel_regularizer = l2(0.01)\n","    )(input_layer)\n","    \n","    conv1 = tfkl.BatchNormalization()(conv1)\n","    \n","    leaky_relu_layer1 = tfkl.LeakyReLU()(conv1)\n","    \n","    pool1 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(leaky_relu_layer1)\n","\n","    \n","\n","    # Layer 2 -----------------------------------------------------------\n","    conv2 = tfkl.Conv2D(\n","        filters=50,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        kernel_regularizer = l2(0.01)\n","    )(pool1)\n","    \n","    conv2 = tfkl.BatchNormalization()(conv2)\n","    \n","    leaky_relu_layer2 = tfkl.LeakyReLU()(conv2)\n","    \n","    pool2 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(leaky_relu_layer2)\n","    \n","\n","\n","    # Layer 3 -----------------------------------------------------------\n","    conv3 = tfkl.Conv2D(\n","        filters=100,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        kernel_regularizer = l2(0.01)\n","    )(pool2)\n","    \n","    conv3 = tfkl.BatchNormalization()(conv3)\n","    \n","    leaky_relu_layer3 = tfkl.LeakyReLU()(conv3)\n","    \n","    pool3 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(leaky_relu_layer3)\n","\n","    \n","\n","    # Layer 4 -----------------------------------------------------------\n","    conv4 = tfkl.Conv2D(\n","        filters=200,\n","        kernel_size=(5, 5),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        kernel_regularizer = l2(0.01)\n","    )(pool3)\n","    \n","    conv4 = tfkl.BatchNormalization()(conv4)\n","    \n","    leaky_relu_layer4 = tfkl.LeakyReLU()(conv4)\n","    \n","    pool4 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(leaky_relu_layer4)\n","\n","    \n","\n","    # Layer 5 -----------------------------------------------------------\n","    conv5 = tfkl.Conv2D(\n","        filters=300,\n","        kernel_size=(5, 5),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        kernel_regularizer = l2(0.01)\n","    )(pool4)\n","    \n","    conv5 = tfkl.BatchNormalization()(conv5)\n","    \n","    leaky_relu_layer5 = tfkl.LeakyReLU()(conv5)\n","    \n","    pool5 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(leaky_relu_layer5)\n","\n","    \n","\n","    # Layer 6 -----------------------------------------------------------\n","    conv6 = tfkl.Conv2D(\n","        filters=400,\n","        kernel_size=(5, 5),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        kernel_regularizer = l2(0.01)\n","    )(pool5)\n","    \n","    conv6 = tfkl.BatchNormalization()(conv6)\n","    \n","    leaky_relu_layer6 = tfkl.LeakyReLU()(conv6)\n","    \n","    pool6 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(leaky_relu_layer6)\n","\n","    \n","\n","    # Layer 7 -----------------------------------------------------------\n","    conv7 = tfkl.Conv2D(\n","        filters=500,\n","        kernel_size=(5, 5),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n","        kernel_regularizer = l2(0.01)\n","    )(pool6)\n","    \n","    conv7 = tfkl.BatchNormalization()(conv7)\n","    \n","    leaky_relu_layer7 = tfkl.LeakyReLU()(conv7)\n","    \n","    \n","    # Global Average Pooling -----------------------------------------------------------\n","    glob_pooling = tfkl.GlobalAveragePooling2D(name='GlobalPooling')(leaky_relu_layer7)\n","\n","\n","    # Dense Layer -----------------------------------------------------------\n","    classifier_layer1 = tfkl.Dense(units=512, name='Classifier1', kernel_initializer=tfk.initializers.GlorotUniform(seed), kernel_regularizer = l2(0.01))(glob_pooling)\n","    \n","    classifier_layer1 = tfkl.BatchNormalization()(classifier_layer1)\n","    \n","    leaky_relu_layer = tfkl.LeakyReLU()(classifier_layer1)\n","    \n","    leaky_relu_layer = tfkl.Dropout(0.3, seed=seed)(leaky_relu_layer)\n","\n","\n","    # Output Layer -----------------------------------------------------------\n","    output_layer = tfkl.Dense(units=14, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='Output')(leaky_relu_layer)\n","\n","    \n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n","\n","    model.compile(\n","        loss=tfk.losses.CategoricalCrossentropy(),\n","        optimizer=tfk.optimizers.Adam(),\n","        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n","    )\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the model and print the shape\n","model = build_model(input_shape)\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Learning Rate Scheduler\n","def scheduler(epoch, lr):\n","   if epoch < 10:\n","     return lr\n","   else:\n","     return lr * tf.math.exp(-0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:08.38662Z","iopub.status.busy":"2021-11-19T14:28:08.385686Z","iopub.status.idle":"2021-11-19T14:28:08.400037Z","shell.execute_reply":"2021-11-19T14:28:08.399308Z","shell.execute_reply.started":"2021-11-19T14:28:08.386571Z"},"papermill":{"duration":0.041747,"end_time":"2021-11-17T09:01:08.321538","exception":false,"start_time":"2021-11-17T09:01:08.279791","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Utility function to create folders and callbacks for training\n","\n","def create_folders_and_callbacks(model_name) :\n","    exps_dir = os.path.join('data_augmentation_experiments')\n","    if not os.path.exists(exps_dir):\n","        os.makedirs(exps_dir)\n","\n","    now = datetime.now().strftime('%b%d_%H-%M-%S')\n","    \n","    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","    if not os.path.exists(exp_dir):\n","        os.makedirs(exp_dir)\n","      \n","    callbacks = []\n","\n","    # Model checkpoint ---------------------------------------------------\n","    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","    if not os.path.exists(ckpt_dir):\n","        os.makedirs(ckpt_dir)\n","\n","    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp'), # filepath is where I want to save the model\n","                                                     save_weights_only=False, # save only the weights ora all the model\n","                                                     save_best_only=True) # if True saves only the results of the best epoch\n","                                                                              \n","    callbacks.append(ckpt_callback)\n","\n","    # Visualize Learning on Tensorboard ----------------------------------\n","    tb_dir = os.path.join(exp_dir, 'tb_logs') # logs where we save the events, where the tensorboard will read the logs\n","    if not os.path.exists(tb_dir):\n","        os.makedirs(tb_dir)\n","      \n","    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                              profile_batch=0,\n","                                              histogram_freq=1)\n","    callbacks.append(tb_callback)\n","\n","    # Early Stopping -----------------------------------------------------\n","    if early_stopping:\n","        es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience_epochs, restore_best_weights=True)\n","        callbacks.append(es_callback)\n","    \n","    # Learning Rate Scheduler --------------------------------------------\n","    LRS_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","    callbacks.append(LRS_callback)\n","    \n","    return callbacks"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-19T14:28:08.751704Z","iopub.status.busy":"2021-11-19T14:28:08.751461Z","iopub.status.idle":"2021-11-19T14:28:30.833003Z","shell.execute_reply":"2021-11-19T14:28:30.831592Z","shell.execute_reply.started":"2021-11-19T14:28:08.751675Z"},"trusted":true},"outputs":[],"source":["callbacks = create_folders_and_callbacks(model_name='Classic_CNN')\n","\n","history = model.fit(\n","    x = aug_train_gen,\n","    class_weight = category_weight,\n","    epochs = epochs,\n","    validation_data = valid_gen,\n","   callbacks = callbacks,\n",").history"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:28:30.834584Z","iopub.status.idle":"2021-11-19T14:28:30.835359Z","shell.execute_reply":"2021-11-19T14:28:30.835094Z","shell.execute_reply.started":"2021-11-19T14:28:30.835065Z"},"trusted":true},"outputs":[],"source":["# Saving the last epoch of the train\n","save_dir = os.path.join('Classic_CNN')\n","model.save(save_dir)"]},{"cell_type":"markdown","metadata":{},"source":["## Some Nice Graphs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:28:30.839324Z","iopub.status.idle":"2021-11-19T14:28:30.840079Z","shell.execute_reply":"2021-11-19T14:28:30.839824Z","shell.execute_reply.started":"2021-11-19T14:28:30.839795Z"},"trusted":true},"outputs":[],"source":["# All the metrics : Accuracy, Precision and Recall\n","ALPHA = 0.5\n","\n","plt.figure(figsize=(20,10))\n","\n","plt.plot(history['accuracy'], label='Accuracy Train', alpha=ALPHA, color='#E64A19')\n","plt.plot(history['val_accuracy'], label='Accuracy Val', alpha=ALPHA, color='#F57C00')\n","\n","plt.plot(history['precision'], label='Precision Train', alpha=ALPHA, color='#388E3C')\n","plt.plot(history['val_precision'], label='Precision Val', alpha=ALPHA, color='#689F38')\n","\n","plt.plot(history['recall'], label='Recall Train', alpha=ALPHA, color='#303F9F')\n","plt.plot(history['val_recall'], label='Recall Val', alpha=ALPHA, color='#1976D2')\n","\n","plt.ylim(.5, 1)\n","plt.title('Metrics')\n","plt.legend(loc='lower right')\n","plt.grid(alpha=.3)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Accuracy Graph\n","plt.figure(figsize=(20,10))\n","\n","plt.plot(history['accuracy'], label='Accuracy Train', alpha=ALPHA, color='#E64A19')\n","plt.plot(history['val_accuracy'], label='Accuracy Val', alpha=ALPHA, color='#F57C00')\n","\n","plt.ylim(.5, 1)\n","plt.title('Accuracy')\n","plt.legend(loc='lower right')\n","plt.grid(alpha=.3)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Precision Graph\n","plt.figure(figsize=(20,10))\n","\n","plt.plot(history['precision'], label='Precision Train', alpha=ALPHA, color='#388E3C')\n","plt.plot(history['val_precision'], label='Precision Val', alpha=ALPHA, color='#689F38')\n","\n","plt.ylim(.5, 1)\n","plt.title('Precision')\n","plt.legend(loc='lower right')\n","plt.grid(alpha=.3)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Recall Graph\n","plt.figure(figsize=(20,10))\n","\n","plt.plot(history['recall'], label='Recall Train', alpha=ALPHA, color='#303F9F')\n","plt.plot(history['val_recall'], label='Recall Val', alpha=ALPHA, color='#1976D2')\n","\n","plt.ylim(.5, 1)\n","plt.title('Recall')\n","plt.legend(loc='lower right')\n","plt.grid(alpha=.3)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2021-11-19T14:28:30.841804Z","iopub.status.idle":"2021-11-19T14:28:30.842442Z","shell.execute_reply":"2021-11-19T14:28:30.842195Z","shell.execute_reply.started":"2021-11-19T14:28:30.84217Z"},"trusted":true},"outputs":[],"source":["# Loss Graph\n","plt.figure(figsize=(15,10))\n","\n","plt.plot(history['loss'], label='Loss Train', alpha=ALPHA, color='#ff7f0e')\n","plt.plot(history['val_loss'], label='Loss Val', alpha=ALPHA, color='#4D61E2')\n","\n","plt.ylim(0, 4)\n","plt.title('Loss')\n","plt.legend(loc='upper right')\n","plt.grid(alpha=.3)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
